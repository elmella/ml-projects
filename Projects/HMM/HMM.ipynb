{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Discrete Hidden Markov Models\n",
    "    Matthew Mella\n",
    "    02/27/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import string\n",
    "import codecs\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems 1-5\n",
    "This is the HMM class that you will be adding functions to throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    Finite state space hidden Markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Problem 1\n",
    "    def __init__(self, A, B, pi):\n",
    "        \"\"\"\n",
    "        Initialize an HMM with parameters A, B, and pi.\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "    \n",
    "    \n",
    "    # Problem 2\n",
    "    def forward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the forward probability matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : ndarray of shape (T, n)\n",
    "            The forward probability matrix\n",
    "        \"\"\"\n",
    "\n",
    "        T = len(z)\n",
    "        n = self.A.shape[0]\n",
    "\n",
    "        # Initialize alpha\n",
    "        alpha = np.zeros((T, n))\n",
    "\n",
    "        # Compute alpha_0\n",
    "        alpha[0] = self.pi * self.B[z[0], :]\n",
    "\n",
    "        # Compute alpha_t\n",
    "        for t in range(1, T):\n",
    "            alpha[t] = self.B[z[t], :] * (alpha[t-1] @ self.A.T)\n",
    "\n",
    "        return alpha\n",
    "    \n",
    "    \n",
    "    # Problem 4\n",
    "    def backward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the backward probability matrix and gamma values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        beta : ndarray of shape (T, n)\n",
    "            The backward probability matrix\n",
    "        gamma : ndarray of shape (T, n)\n",
    "            The state probability matrix\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute alpha with forward_pass\n",
    "        alpha = self.forward_pass(z)\n",
    "\n",
    "        T = len(z)\n",
    "        n = self.A.shape[0]\n",
    "\n",
    "        # Initialize beta\n",
    "        beta = np.zeros((T,n))\n",
    "\n",
    "        # Set beta_T\n",
    "        beta[-1, :] = 1\n",
    "\n",
    "        # Compute beta_t\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            beta[t, :] = self.A.T @ (self.B[z[t + 1], :] * beta[t + 1, :])\n",
    "\n",
    "        # Compute gamma\n",
    "        gamma = alpha * beta / np.sum(alpha[-1, :])\n",
    "\n",
    "        # Return beta and gamma\n",
    "        return beta, gamma\n",
    "    \n",
    "    # Problem 5\n",
    "    def viterbi_algorithm(self, z):\n",
    "        \"\"\"\n",
    "        Compute the most likely hidden state sequence using the Viterbi algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x*: ndarray of shape (T,)\n",
    "            The most likely state sequence\n",
    "        \"\"\"\n",
    "        T = len(z)\n",
    "        n = self.A.shape[0]\n",
    "\n",
    "        # Initialize eta\n",
    "        eta = np.zeros((T, n))\n",
    "\n",
    "        # Compute eta_0\n",
    "        eta[0] = self.B[z[0], :] * self.pi\n",
    "\n",
    "        # Compute eta_t\n",
    "        for t in range(1, T):\n",
    "            eta[t] = np.max(self.B[z[t], :, None] * self.A * eta[t-1], axis = 1)\n",
    "\n",
    "\n",
    "        # Backtrack to find the most likely state sequence\n",
    "        xstar = np.zeros(T, dtype=int)\n",
    "        \n",
    "        # Set the last state\n",
    "        xstar[-1] = np.argmax(eta[-1])\n",
    "\n",
    "        # Compute xstar_t\n",
    "        for t in range(T - 1, 0, -1):\n",
    "            xstar[t-1] = np.argmax(self.A[xstar[t],:] * eta[t-1])\n",
    "\n",
    "        # Return the most likely state sequence\n",
    "        return xstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 test case\n",
    "\n",
    "Use the following HMM and code to test your HMM class.\n",
    "Compare the output to `forward_pass` with the lab pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009629599999999999\n"
     ]
    }
   ],
   "source": [
    "pi = np.array([.6, .4])\n",
    "A = np.array([[.7, .4],[.3, .6]])\n",
    "B = np.array([[.1,.7],[.4, .2],[.5, .1]])\n",
    "z_example = np.array([0, 1, 0, 2])\n",
    "example_hmm = HMM(A, B, pi)\n",
    "\n",
    "alpha=example_hmm.forward_pass(z_example)\n",
    "print(np.sum(alpha[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Consider the following (very simplified) model of the price of a stock over time as an HMM.\n",
    "The observation states will be the change in the value of the stock.\n",
    "For simplicity, we will group these into five values: large decrease, small decrease, no change, small increase, large increase, labeled as integers from 0 to 4.\n",
    "The hidden state will be the overall trends of the market.\n",
    "We'll consider the market to have three possible states: declining in value (bear market), not changing in value (stagnant), and increasing in value (bull market), labeled as integers from 0 to 2.\n",
    "Let the HMM modeling this scenario have parameters\n",
    "$$\n",
    "\\boldsymbol\\pi=\\begin{bmatrix}\n",
    "1/3 \\\\ 1/3 \\\\ 1/3\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "A=\\begin{bmatrix}\n",
    "0.5 & 0.3 & 0 \\\\\n",
    "0.5 & 0.3 & 0.3 \\\\\n",
    "0 & 0.4 & 0.7\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "B=\\begin{bmatrix}\n",
    "0.3 & 0.1 & 0 \\\\\n",
    "0.3 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.1 & 0.2 & 0.4 \\\\\n",
    "0 & 0.1 & 0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The file `stocks.npy` contains a sequence of 50 observations drawn from this HMM.\n",
    "What is the probability of this observation sequence given these model parameters?\n",
    "Use your implementation of the forward pass algorithm from Problem 2 to find the answer.\n",
    "Note that the answer is very small, because there are lots of possible observation sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.67111511453778e-34\n"
     ]
    }
   ],
   "source": [
    "# HMM parameter setup\n",
    "pi = np.array([1/3, 1/3, 1/3])\n",
    "A = np.array([\n",
    "    [0.5, 0.3, 0.0],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [0.0, 0.4, 0.7]\n",
    "])\n",
    "B = np.array([\n",
    "    [0.3, 0.1, 0.0],\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.0, 0.1, 0.2]\n",
    "])\n",
    "\n",
    "hmm = HMM(A, B, pi)\n",
    "\n",
    "data = np.load('stocks.npy')\n",
    "\n",
    "alpha = hmm.forward_pass(data)\n",
    "\n",
    "print(np.sum(alpha[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Create a method `backward_pass` in your HMM class to implement the backward pass algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return two arrays of the $\\beta_t(i)$ and $\\gamma_t(i)$ values.\n",
    "\n",
    "Test your function on the example HMM, and compare the output with the lab pdf.\n",
    "\n",
    "With your function and the stock model from Problem 3, answer the following question: given the observation sequence in `stocks.npy`, what is the most likely initial hidden state $X_0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0302  0.02792]\n",
      " [0.0812  0.1244 ]\n",
      " [0.38    0.26   ]\n",
      " [1.      1.     ]]\n",
      "[[0.18816981 0.81183019]\n",
      " [0.51943175 0.48056825]\n",
      " [0.22887763 0.77112237]\n",
      " [0.8039794  0.1960206 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test case; compare your output with what is in the lab pdf\n",
    "beta, gamma = example_hmm.backward_pass(z_example)\n",
    "print(beta)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely initial hidden state is 1\n"
     ]
    }
   ],
   "source": [
    "# HMM parameter setup\n",
    "pi = np.array([1/3, 1/3, 1/3])\n",
    "A = np.array([\n",
    "    [0.5, 0.3, 0.0],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [0.0, 0.4, 0.7]\n",
    "])\n",
    "B = np.array([\n",
    "    [0.3, 0.1, 0.0],\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.0, 0.1, 0.2]\n",
    "])\n",
    "\n",
    "hmm = HMM(A, B, pi)\n",
    "\n",
    "data = np.load('stocks.npy')\n",
    "\n",
    "beta, gamma = hmm.backward_pass(data)\n",
    "\n",
    "# find most likely initial hidden state\n",
    "initial_state = np.argmax(gamma[0])\n",
    "print(\"The most likely initial hidden state is\", initial_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "Creating a method `viterbi_algorithm` in your HMM class to implement the Viterbi algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return the most likely state sequence $\\mathbf{x}^*$.\n",
    "\n",
    "Test your function on the example HMM and compare output with the lab pdf.\n",
    "\n",
    "Apply your function to the stock market HMM from Problem 3.\n",
    "With the observaition sequence from `stocks.npy`, what is the most likely sequence of hidden states?\n",
    "Is the initial state of the most likely sequence the same as the most likely initial state you found in Problem 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Test case\n",
    "xstar = example_hmm.viterbi_algorithm(z_example)\n",
    "print(xstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely sequence is:\n",
      "[0 0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 0 0 0 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# HMM parameter setup\n",
    "pi = np.array([1/3, 1/3, 1/3])\n",
    "A = np.array([\n",
    "    [0.5, 0.3, 0.0],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [0.0, 0.4, 0.7]\n",
    "])\n",
    "B = np.array([\n",
    "    [0.3, 0.1, 0.0],\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.0, 0.1, 0.2]\n",
    "])\n",
    "\n",
    "hmm = HMM(A, B, pi)\n",
    "\n",
    "data = np.load('stocks.npy')\n",
    "\n",
    "beta, gamma = hmm.backward_pass(data)\n",
    "\n",
    "# find most likely sequence\n",
    "sequence = hmm.viterbi_algorithm(data)\n",
    "\n",
    "print(\"The most likely sequence is:\")\n",
    "print(sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For problem 4, we find the most likely state is 1 for t0, but in this case, as we consider the sequence as a whole, the most likely state starts with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "Train a `hmmlearn.hmm.CategoricalHMM` on `declaration.txt`. Use `N=2` states and `M=len(set(obs))=27` observation values (26 lower case characters and 1 whitespace character).\n",
    "Use `n_iter=200` and `tol=1e-4`.\n",
    "\n",
    "Once the learning algorithm converges, analyze the state observation matrix $B$. Note which rows correspond to the largest and smallest probability values in each column of $B$, and check the corresponding characters. The HMM should have detected a vowel state and a consonant state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_translate(a, my_dict):\n",
    "    # translate numpy array from symbols to state numbers or vice versa\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "def prep_data(filename):\n",
    "    \"\"\"\n",
    "    Reads in the file and prepares it for use in an HMM.\n",
    "    Returns:\n",
    "        symbols (dict): a dictionary that maps characters to their integer values\n",
    "        obs_sequence (ndarray): an array of integers representing the read-in text\n",
    "    \"\"\"\n",
    "    # Get the data as a single string\n",
    "    with codecs.open(filename, encoding='utf-8') as f:\n",
    "        data=f.read().lower()  # and convert to all lower case\n",
    "    # remove punctuation and newlines\n",
    "    remove_punct_map = {ord(char): \n",
    "                        None for char in string.punctuation+\"\\n\\r\"}\n",
    "    data = data.translate(remove_punct_map)\n",
    "    # make a list of the symbols in the data\n",
    "    symbols = sorted(list(set(data)))\n",
    "    # convert the data to a NumPy array of symbols\n",
    "    a = np.array(list(data))\n",
    "    # make a conversion dictionary from symbols to state numbers\n",
    "    symbols_to_obsstates = {x:i for i,x in enumerate(symbols)}\n",
    "    # convert the symbols in a to state numbers\n",
    "    obs_sequence = vec_translate(a,symbols_to_obsstates)\n",
    "    return symbols, obs_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalHMM(n_components=2, n_features=27, n_iter=200,\n",
       "               random_state=RandomState(MT19937) at 0x105A0E840, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalHMM</label><div class=\"sk-toggleable__content\"><pre>CategoricalHMM(n_components=2, n_features=27, n_iter=200,\n",
       "               random_state=RandomState(MT19937) at 0x105A0E840, tol=0.0001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalHMM(n_components=2, n_features=27, n_iter=200,\n",
       "               random_state=RandomState(MT19937) at 0x105A0E840, tol=0.0001)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols, obs = prep_data('declaration.txt')\n",
    "h = hmm.CategoricalHMM(n_components=2, n_iter=200, tol=1e-4)\n",
    "h.fit(obs.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.2987, 0.0503\n",
      "a, 0.1319, 0.0000\n",
      "b, 0.0000, 0.0226\n",
      "c, 0.0000, 0.0437\n",
      "d, 0.0000, 0.0599\n",
      "e, 0.2376, 0.0000\n",
      "f, 0.0000, 0.0428\n",
      "g, 0.0000, 0.0309\n",
      "h, 0.0000, 0.0829\n",
      "i, 0.1242, 0.0000\n",
      "j, 0.0000, 0.0038\n",
      "k, 0.0004, 0.0030\n",
      "l, 0.0000, 0.0542\n",
      "m, 0.0000, 0.0342\n",
      "n, 0.0000, 0.1147\n",
      "o, 0.1376, 0.0036\n",
      "p, 0.0000, 0.0328\n",
      "q, 0.0000, 0.0014\n",
      "r, 0.0000, 0.1009\n",
      "s, 0.0000, 0.1135\n",
      "t, 0.0000, 0.1520\n",
      "u, 0.0578, 0.0000\n",
      "v, 0.0000, 0.0176\n",
      "w, 0.0000, 0.0230\n",
      "x, 0.0000, 0.0021\n",
      "y, 0.0117, 0.0092\n",
      "z, 0.0000, 0.0010\n"
     ]
    }
   ],
   "source": [
    "B = h.emissionprob_.T\n",
    "for i in range(len(B)):\n",
    "    print(u\"{}, {:0.4f}, {:0.4f}\"\n",
    "                .format(symbols[i], *B[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that, in column 0, the vowels all have a relatively large value, but their value is 0 for column 1. Similarly, all of the constants have a zero value in column 0, but a nonzero  value in column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "\n",
    "Repeat the same calculation with `WarAndPeace.txt` with 2 hidden states. Interpret/explain your results. Which Cyrillic characters appear to be vowels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.0877, 0.2146\n",
      "а, 0.1760, 0.0000\n",
      "б, 0.0000, 0.0250\n",
      "в, 0.0000, 0.0655\n",
      "г, 0.0000, 0.0296\n",
      "д, 0.0000, 0.0385\n",
      "е, 0.1427, 0.0180\n",
      "ж, 0.0000, 0.0140\n",
      "з, 0.0000, 0.0252\n",
      "и, 0.1315, 0.0017\n",
      "й, 0.0000, 0.0149\n",
      "к, 0.0010, 0.0497\n",
      "л, 0.0000, 0.0719\n",
      "м, 0.0000, 0.0381\n",
      "н, 0.0000, 0.0973\n",
      "о, 0.2407, 0.0000\n",
      "п, 0.0062, 0.0346\n",
      "р, 0.0000, 0.0597\n",
      "с, 0.0280, 0.0513\n",
      "т, 0.0000, 0.0780\n",
      "у, 0.0590, 0.0000\n",
      "ф, 0.0003, 0.0018\n",
      "х, 0.0000, 0.0111\n",
      "ц, 0.0000, 0.0049\n",
      "ч, 0.0038, 0.0167\n",
      "ш, 0.0000, 0.0109\n",
      "щ, 0.0000, 0.0047\n",
      "ъ, 0.0003, 0.0003\n",
      "ы, 0.0376, 0.0000\n",
      "ь, 0.0433, 0.0009\n",
      "э, 0.0066, 0.0000\n",
      "ю, 0.0024, 0.0079\n",
      "я, 0.0328, 0.0128\n",
      "ё, 0.0001, 0.0000\n"
     ]
    }
   ],
   "source": [
    "symbols, obs = prep_data('WarAndPeace.txt')\n",
    "h = hmm.CategoricalHMM(n_components=2, n_iter=200, tol=1e-4)\n",
    "h.fit(obs.reshape(-1,1))\n",
    "B = h.emissionprob_.T\n",
    "for i in range(len(B)):\n",
    "    print(u\"{}, {:0.4f}, {:0.4f}\"\n",
    "                .format(symbols[i], *B[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see a split among characters in the 2 columns. It looks like the vowels have a larger numerical value in column 0 than in column 1.\n",
    "\n",
    "From this, it looks like the vowels are \"а, и, o, у, ы, ь, э, я\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
