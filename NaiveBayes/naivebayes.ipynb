{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages into spam or ham.\n",
    "    '''\n",
    "    # Problem 1\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Compute the values P(C=Ham), P(C=Spam), and P(x_i|C) to fit the model.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "        '''\n",
    "        \n",
    "        hamMask = y == 'ham'\n",
    "        spamMask = y == 'spam'\n",
    "\n",
    "        self.p_ham = np.sum(hamMask) / len(y)\n",
    "        self.p_spam = np.sum(spamMask) / len(y)\n",
    "\n",
    "        ham = X[hamMask]\n",
    "        spam = X[spamMask]\n",
    "\n",
    "        hamWords = []\n",
    "        spamWords = []\n",
    "\n",
    "        hamWords = [word for sublist in ham.str.split() for word in sublist]\n",
    "        spamWords = [word for sublist in spam.str.split() for word in sublist]\n",
    "\n",
    "        self.trainingWords = hamWords + spamWords\n",
    "\n",
    "        lenHamWords = len(hamWords)\n",
    "        lenSpamWords = len(spamWords)\n",
    "        \n",
    "        ham_probs = Counter(hamWords)\n",
    "        spam_probs = Counter(spamWords)\n",
    "\n",
    "        for word in ham_probs.keys():\n",
    "            ham_probs[word] = (ham_probs[word] + 1) / (lenHamWords + 2)\n",
    "            if word not in spam_probs.keys():\n",
    "                spam_probs[word] = 1 / (lenSpamWords + 2)\n",
    "\n",
    "        for word in spam_probs.keys():\n",
    "            spam_probs[word] = (spam_probs[word] + 1) / (lenSpamWords + 2)\n",
    "            if word not in ham_probs.keys():\n",
    "                ham_probs[word] = 1 / (lenHamWords + 2)\n",
    "\n",
    "        self.ham_probs = ham_probs\n",
    "        self.spam_probs = spam_probs\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Problem 2\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k,x)) for each x in X and for each class.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Log probability each message is ham or spam.\n",
    "                Column 0 is ham, column 1 is spam.\n",
    "        '''\n",
    "        messages = X.str.split()\n",
    "\n",
    "        ham_probs = []\n",
    "        spam_probs = []\n",
    "\n",
    "        p_ham = np.log(self.p_ham)\n",
    "        p_spam = np.log(self.p_spam)\n",
    "\n",
    "        logPointFive = np.log(0.5)\n",
    "\n",
    "        for message in messages:\n",
    "            ham_prob = p_ham\n",
    "            spam_prob = p_spam\n",
    "            for word in message:\n",
    "                if word not in self.trainingWords:\n",
    "                    ham_prob += logPointFive\n",
    "                    spam_prob += logPointFive\n",
    "                else:\n",
    "                    ham_prob += np.log(self.ham_probs[word])\n",
    "                    spam_prob += np.log(self.spam_probs[word])\n",
    "            ham_probs.append(ham_prob)\n",
    "            spam_probs.append(spam_prob)\n",
    "\n",
    "        ham_probs = np.array(ham_probs)\n",
    "        spam_probs = np.array(spam_probs)\n",
    "\n",
    "        return np.vstack((ham_probs, spam_probs)).T\n",
    "\n",
    "    # Problem 3\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the labels of each row in X, using self.predict_proba().\n",
    "        The label will be a string that is either 'spam' or 'ham'.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        probs = self.predict_proba(X)\n",
    "        labels = []\n",
    "        for prob in probs:\n",
    "            if prob[0] < prob[1]:\n",
    "                labels.append('spam')\n",
    "            else:\n",
    "                labels.append('ham')\n",
    "\n",
    "        return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaiveBayesFilter at 0x17839e9b0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sms_spam_collection.csv')\n",
    "X = df['Message']\n",
    "y = df['Label']\n",
    "nb = NaiveBayesFilter()\n",
    "nb.fit(X[:300], y[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003147128245476003\n",
      "0.004166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(nb.ham_probs['out'])\n",
    "print(nb.spam_probs['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -30.8951931 ,  -35.42156791],\n",
       "       [-108.85464069,  -91.7016556 ],\n",
       "       [ -74.65014875,  -88.70768216],\n",
       "       [-164.94297917, -133.84807453],\n",
       "       [-127.17743715, -101.32098062]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict_proba(X[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'spam', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(X[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Volume 3: Naive Bayes Classifiers.\"\"\"\n",
    "\n",
    "def prob4():\n",
    "    \"\"\"\n",
    "    Create a train-test split and use it to train a NaiveBayesFilter.\n",
    "    Predict the labels of the test set.\n",
    "    \n",
    "    Compute and return the following two values as a tuple:\n",
    "     - What proportion of the spam messages in the test set were correctly identified by the classifier?\n",
    "     - What proportion of the ham messages were incorrectly identified?\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('sms_spam_collection.csv')\n",
    "    X, y = df['Message'], df['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    nb = NaiveBayesFilter()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    correct_spam = np.sum((y_pred == 'spam') & (y_test == 'spam'))\n",
    "    incorrect_ham = np.sum((y_pred == 'spam') & (y_test == 'ham'))\n",
    "    return correct_spam / np.sum(y_test == 'spam'), incorrect_ham / np.sum(y_test == 'ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5\n",
    "class PoissonBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages in to spam or ham.\n",
    "    This classifier assumes that words are distributed like\n",
    "    Poisson random variables.\n",
    "    '''\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Compute the values P(C=Ham), P(C=Spam), and r_{i,k} to fit the model.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "        '''\n",
    "        \n",
    "        # Get the number of ham and spam messages\n",
    "        hamMask = y == 'ham'\n",
    "        spamMask = y == 'spam'\n",
    "\n",
    "        # Calculate the probability of ham and spam\n",
    "        self.p_ham = np.sum(hamMask) / len(y)\n",
    "        self.p_spam = np.sum(spamMask) / len(y)\n",
    "\n",
    "        # Get the ham and spam messages\n",
    "        ham = X[hamMask]\n",
    "        spam = X[spamMask]\n",
    "\n",
    "        # Get the words from the ham and spam messages\n",
    "        hamWords = []\n",
    "        spamWords = []\n",
    "        hamWords = [word for sublist in ham.str.split() for word in sublist]\n",
    "        spamWords = [word for sublist in spam.str.split() for word in sublist]\n",
    "\n",
    "        self.N_ham = len(hamWords)\n",
    "        self.N_spam = len(spamWords)\n",
    "        # Get the unique words from the ham and spam messages\n",
    "        self.trainingWords = list(set(hamWords + spamWords))\n",
    "\n",
    "        # Get the length of the ham and spam messages\n",
    "        \n",
    "        # Calculate the rate of each word in the ham and spam messages\n",
    "        ham_rates = Counter(hamWords)\n",
    "        spam_rates = Counter(spamWords)\n",
    "\n",
    "        # Add 1 to each word count and divide by the total number of words + 2\n",
    "        for word in ham_rates.keys():\n",
    "            ham_rates[word] = (ham_rates[word] + 1) / (self.N_ham + 2)\n",
    "            # Add words that are in the spam messages but not in the ham messages\n",
    "            if word not in spam_rates.keys():\n",
    "                spam_rates[word] = 1 / (self.N_spam + 2)\n",
    "\n",
    "        for word in spam_rates.keys():\n",
    "            spam_rates[word] = (spam_rates[word] + 1) / (self.N_spam + 2)\n",
    "            # Add words that are in the ham messages but not in the spam messages\n",
    "            if word not in ham_rates.keys():\n",
    "                ham_rates[word] = 1 / (self.N_ham + 2)\n",
    "\n",
    "        # Set the ham and spam rates to the calculated rates\n",
    "        self.ham_rates = ham_rates\n",
    "        self.spam_rates = spam_rates\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k,x)) for each x in X and for each class.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Log probability each message is ham or spam.\n",
    "                Column 0 is ham, column 1 is spam.\n",
    "        '''\n",
    "        # Split the messages into words\n",
    "        messages = X.str.split()\n",
    "\n",
    "        ham_probs = []\n",
    "        spam_probs = []\n",
    "\n",
    "        # Get the log of the probability of ham and spam\n",
    "        p_ham = np.log(self.p_ham)\n",
    "        p_spam = np.log(self.p_spam)\n",
    "\n",
    "        # Set the default rate of ham and spam\n",
    "        hamNotFound = 1 / (self.N_ham + 2)\n",
    "        spamNotFound = 1 / (self.N_spam + 2)\n",
    "        \n",
    "        # Iterate through each message\n",
    "        for message in messages:\n",
    "\n",
    "            # Get the length of the message\n",
    "            n = len(message)\n",
    "            \n",
    "            # set the probability of ham and spam to the log of the probability of ham and spam\n",
    "            ham_prob = p_ham\n",
    "            spam_prob = p_spam\n",
    "            for word in np.unique(message):\n",
    "                \n",
    "                # If the word is not in the training set, set the rate to the default rate\n",
    "                if word not in self.trainingWords:\n",
    "                    ham_r = hamNotFound\n",
    "                    spam_r = spamNotFound\n",
    "                # Otherwise, set the rate to the log of the rate of the word\n",
    "                else:\n",
    "                    ham_r = self.ham_rates[word]\n",
    "                    spam_r = self.spam_rates[word]\n",
    "                \n",
    "                # get the count of the word in the message\n",
    "                ni = message.count(word)\n",
    "\n",
    "                # Calculate the probability of the word in the message\n",
    "                ham_eq = ((ham_r * n)**ni * np.exp(-ham_r * n)) / math.factorial(ni)\n",
    "                spam_eq = ((spam_r * n)**ni * np.exp(-spam_r * n)) / math.factorial(ni)\n",
    "\n",
    "                # Add the log of the probability of the word to the log of the probability of the message\n",
    "                ham_prob += np.log(ham_eq)\n",
    "                spam_prob += np.log(spam_eq)\n",
    "\n",
    "            # append the log of the probability of the message to the ham and spam probabilities\n",
    "            ham_probs.append(ham_prob)\n",
    "            spam_probs.append(spam_prob)\n",
    "\n",
    "        # Convert the ham and spam probabilities to arrays\n",
    "        ham_probs = np.array(ham_probs)\n",
    "        spam_probs = np.array(spam_probs)\n",
    "\n",
    "        # Return the ham and spam probabilities as a stacked array\n",
    "        return np.vstack((ham_probs, spam_probs)).T\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the labels of each row in X, using self.predict_proba().\n",
    "        The label will be a string that is either 'spam' or 'ham'.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        # Get the probabilities of ham and spam\n",
    "        probs = self.predict_proba(X)\n",
    "        labels = []\n",
    "        # Iterate through each probability\n",
    "        for prob in probs:\n",
    "            # If the probability of spam is greater than the probability of ham, append spam\n",
    "            if prob[0] < prob[1]:\n",
    "                labels.append('spam')\n",
    "            # Otherwise, append ham\n",
    "            else:\n",
    "                labels.append('ham')\n",
    "\n",
    "        # Convert the labels to an array\n",
    "        return np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prob6():\n",
    "    \"\"\"\n",
    "    Create a train-test split and use it to train a PoissonBayesFilter.\n",
    "    Predict the labels of the test set.\n",
    "    \n",
    "    Compute and return the following two values as a tuple:\n",
    "     - What proportion of the spam messages in the test set were correctly identified by the classifier?\n",
    "     - What proportion of the ham messages were incorrectly identified?\n",
    "    \"\"\"\n",
    "    # Read in the data\n",
    "    df = pd.read_csv('sms_spam_collection.csv')\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X, y = df['Message'], df['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Create a NaiveBayesFilter and fit it to the training data\n",
    "    pb = PoissonBayesFilter()\n",
    "    pb.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the test data\n",
    "    y_pred = pb.predict(X_test)\n",
    "\n",
    "    # Calculate the proportion of spam messages correctly identified and the proportion of ham messages incorrectly identified\n",
    "    correct_spam = np.sum((y_pred == 'spam') & (y_test == 'spam'))\n",
    "    incorrect_ham = np.sum((y_pred == 'spam') & (y_test == 'ham'))\n",
    "\n",
    "    # Return the proportions\n",
    "    return correct_spam / np.sum(y_test == 'spam'), incorrect_ham / np.sum(y_test == 'ham')\n",
    "\n",
    "    \n",
    "# Problem 7\n",
    "def sklearn_naive_bayes(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Use sklearn's methods to transform X_train and X_test, create a\n",
    "    naïve Bayes filter, and classify the provided test set.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pandas.Series): messages to train on\n",
    "        y_train (pandas.Series): labels for X_train\n",
    "        X_test  (pandas.Series): messages to classify\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): classification of X_test\n",
    "    '''\n",
    "    # Create a CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # Create a MultinomialNB classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(train_counts, y_train)\n",
    "\n",
    "    # Transform the test data\n",
    "    test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "    # Return the predictions\n",
    "    return clf.predict(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012588512981904013\n",
      "0.004166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Example model trained on the first 300 data points\n",
    "pb = PoissonBayesFilter()\n",
    "pb.fit(X[:300], y[:300])\n",
    "# Check spam and ham rate of 'in'\n",
    "print(pb.ham_rates['in'])\n",
    "print(pb.spam_rates['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -37.14113097,  -38.21684121],\n",
       "       [-112.61977379,  -83.54540076],\n",
       "       [ -55.70966168,  -63.83191882],\n",
       "       [-130.02471282,  -90.15525611],\n",
       "       [-102.36539804,  -69.55261684]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.predict_proba(X[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'spam', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.predict(X[800:805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9558011049723757, 0.017326732673267328)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob6()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
